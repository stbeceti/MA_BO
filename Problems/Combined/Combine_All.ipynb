{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f3da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_wd = os.getcwd()\n",
    "parent_parent = os.path.dirname(os.path.dirname(current_wd))\n",
    "os.chdir(parent_parent)\n",
    "\n",
    "from MyImports import *\n",
    "hv.extension('bokeh')\n",
    "\n",
    "os.chdir(current_wd)\n",
    "\n",
    "\n",
    "seed = 42\n",
    "pyro.set_rng_seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de069e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.linspace(0.1,10,100, dtype=torch.float64)\n",
    "X2 = torch.linspace(0.1,10,100, dtype=torch.float64)\n",
    "XX1, XX2 = torch.meshgrid((X1, X2), indexing='xy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74ddac",
   "metadata": {},
   "source": [
    "## Objective functions 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _objective2D(x1, x2, noise):\n",
    "    \n",
    "    def _inner_objective(x1, x2):\n",
    "        return 3*(1-x1)**2 * torch.exp(-x1**2 - (x2+1)**2) - 10*(0.2*x1 - x1**3 - x2**5) * torch.exp(-x1**2 - x2**2) - 1/3.* torch.exp(-(x1+1)**2 - x2**2)\n",
    "    \n",
    "    if noise != 0.:\n",
    "        res = [_inner_objective(x1i, x2i) + torch.distributions.Normal(0, noise).sample() for x1i, x2i in zip(x1, x2)]\n",
    "        \n",
    "        return torch.cat(res, dim=0).reshape(-1)\n",
    "    \n",
    "    return _inner_objective(x1, x2).reshape(-1)\n",
    "\n",
    "\n",
    "def scale(from_, to_):\n",
    "    \"\"\"\n",
    "    Converts scale of input from_ to the scales of input to_.\n",
    "    \"\"\"\n",
    "    a1 = from_ if from_.shape[-1] == 1 else from_ - from_.min()\n",
    "    a2 = a1 / a1.max()\n",
    "    a3 = a2 * abs(to_.max() - to_.min())\n",
    "    a4 = a3 + to_.min()\n",
    "    return a4\n",
    "\n",
    "\n",
    "def Objective2D_ds_10(x1, x2=0., noise=.3):\n",
    "    \"\"\"\n",
    "    Bounds [0, 10] for x1, [0, 10] for x2.\n",
    "    \"\"\"\n",
    "    dtype = x1.dtype\n",
    "    x1 = scale(torch.cat((x1, torch.tensor([[0], [10]], dtype=torch.float64)), dim=0), np.array([-2.5, 2.5]))[:-2]\n",
    "    x2 = scale(torch.cat((x2, torch.tensor([[0], [10]], dtype=torch.float64)), dim=0), np.array([-2.5, 2.5]))[:-2]\n",
    "    x2 = (x2*10./5).round() *5/10.\n",
    "    \n",
    "    return _objective2D(x1, x2, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "\n",
    "obj1 = alpine2D_ds\n",
    "\n",
    "def obj2(x1, x2, noise):\n",
    "    return 0.8 * alpine2D_ds(x1, x2, noise)\n",
    "\n",
    "obj3 = Objective2D_ds_10\n",
    "\n",
    "def obj4(x1, x2, noise):\n",
    "    return 0.9* Objective2D_ds_10(x1, x2, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obj1 = obj1(x1=XX1.reshape(-1,1), x2=XX2.reshape(-1,1), noise=0.)\n",
    "data = [(x.item(), y.item(), z.item()) for x,y,z in zip(XX1.flatten(), XX2.flatten(), y_obj1)]\n",
    "mean_heat1 = hv.HeatMap(data).opts(cmap='RdBu_r', width=430, height=400, colorbar=True,\n",
    "                                   title='Objective function 1',\n",
    "                                   xlabel='continuous variable',\n",
    "                                   ylabel='discrete variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obj2 = obj2(x1=XX1.reshape(-1,1), x2=XX2.reshape(-1,1), noise=0.)\n",
    "data = [(x.item(), y.item(), z.item()) for x,y,z in zip(XX1.flatten(), XX2.flatten(), y_obj2)]\n",
    "mean_heat2 = hv.HeatMap(data).opts(cmap='RdBu_r', width=430, height=400, colorbar=True,\n",
    "                                   title='Objective function 2',\n",
    "                                   xlabel='continuous variable',\n",
    "                                   ylabel='discrete variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74786fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obj3 = obj3(x1=XX1.reshape(-1,1), x2=XX2.reshape(-1,1), noise=0.)\n",
    "data = [(x.item(), y.item(), z.item()) for x,y,z in zip(XX1.flatten(), XX2.flatten(), y_obj3)]\n",
    "mean_heat3 = hv.HeatMap(data).opts(cmap='RdBu_r', width=430, height=400, colorbar=True,\n",
    "                                   title='Objective function 3',\n",
    "                                   xlabel='continuous variable',\n",
    "                                   ylabel='discrete variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obj4 = obj4(x1=XX1.reshape(-1,1), x2=XX2.reshape(-1,1), noise=0.)\n",
    "data = [(x.item(), y.item(), z.item()) for x,y,z in zip(XX1.flatten(), XX2.flatten(), y_obj4)]\n",
    "mean_heat4 = hv.HeatMap(data).opts(cmap='RdBu_r', width=430, height=400, colorbar=True,\n",
    "                                   title='Objective function 4',\n",
    "                                   xlabel='continuous variable',\n",
    "                                   ylabel='discrete variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af547476",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = {'title':15, 'xlabel': 14, 'ylabel': 14, 'legend': 14}\n",
    "\n",
    "(mean_heat1.opts(fontsize=fontsize) + mean_heat2.opts(fontsize=fontsize) + mean_heat3.opts(fontsize=fontsize) + \n",
    " mean_heat4.opts(fontsize=fontsize)).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973190b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lim = [y_obj3.min()-0.5, y_obj3.max() + 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfc4bb",
   "metadata": {},
   "source": [
    "## Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de44d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "X_test1 = torch.cat((XX1.reshape(-1,1),\n",
    "                     XX2.reshape(-1,1),\n",
    "                     torch.tensor([[1,0,0,0]], dtype=torch.float64).repeat(len(XX1.flatten()), 1)), dim=1)\n",
    "X_test2 = torch.cat((XX1.reshape(-1,1),\n",
    "                     XX2.reshape(-1,1),\n",
    "                     torch.tensor([[0,1,0,0]], dtype=torch.float64).repeat(len(XX1.flatten()), 1)), dim=1)\n",
    "X_test3 = torch.cat((XX1.reshape(-1,1),\n",
    "                     XX2.reshape(-1,1),\n",
    "                     torch.tensor([[0,0,1,0]], dtype=torch.float64).repeat(len(XX1.flatten()), 1)), dim=1)\n",
    "X_test4 = torch.cat((XX1.reshape(-1,1),\n",
    "                     XX2.reshape(-1,1),\n",
    "                     torch.tensor([[0,0,0,1]], dtype=torch.float64).repeat(len(XX1.flatten()), 1)), dim=1)\n",
    "\n",
    "X_test = torch.cat((X_test1, X_test2, X_test3, X_test4), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ebdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCateg(model, categ):\n",
    "    X = model.X.T[2:].T\n",
    "    indices = [(x == categ).all().item() for x in X]\n",
    "    \n",
    "    return model.X[indices], model.y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152447a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObjective(model, X_test):\n",
    "    x_next = model.next(X_test)\n",
    "    if (x_next.T[2:].T == torch.tensor([1,0,0,0])).all().item():\n",
    "        return obj1\n",
    "    elif (x_next.T[2:].T == torch.tensor([0,1,0,0])).all().item():\n",
    "        return obj2\n",
    "    elif (x_next.T[2:].T == torch.tensor([0,0,1,0])).all().item():\n",
    "        return obj3\n",
    "    elif (x_next.T[2:].T == torch.tensor([0,0,0,1])).all().item():\n",
    "        return obj4\n",
    "    else:\n",
    "        raise AttributeError('invalid category: ', x_next.T[2:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf24d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHmaps(init_model,\n",
    "             num_iter,\n",
    "             xlabel='continuous variable',\n",
    "             ylabel='numerical discrete variable',\n",
    "             fontsize = {'title': 15, 'xlabel': 14, 'ylabel': 14, 'legend': 14},\n",
    "             width = 400,\n",
    "             height = 350,\n",
    "             init_samples=None):\n",
    "    \n",
    "    hmaps = OrderedDict()\n",
    "    former_objective = obj1\n",
    "    \n",
    "    # outer loop: defines current categorical context\n",
    "    for x_test, obj, idx in zip([X_test1, X_test2, X_test3, X_test4],\n",
    "                                [obj1, obj2, obj3, obj4],\n",
    "                                [0,1,2,3]):\n",
    "        \n",
    "        txt = 'Categ {}, '.format(idx+1)\n",
    "        # middle loop: num_iter times runs per categorical context\n",
    "        \n",
    "        for j in range(num_iter):\n",
    "            \n",
    "            length_scale = init_model.kernel.lengthscale_unconstrained.exp()\n",
    "            output_scale = init_model.kernel.variance_unconstrained.exp().sqrt()\n",
    "            \n",
    "            print(txt + 'Iteration {}: \\n noise: {:.2f}, l: {:.2f}, lambda: {:.2f}'.format(j,\n",
    "                                                                                            init_model.noise,\n",
    "                                                                                            length_scale,\n",
    "                                                                                            output_scale))\n",
    "            if noise == 0.:\n",
    "                lengthscale.append(length_scale)\n",
    "                outputscale.append(output_scale)\n",
    "                noise_.append(init_model.noise)\n",
    "            else:\n",
    "                lengthscale_noisy.append(length_scale)\n",
    "                outputscale_noisy.append(output_scale)\n",
    "                noise_noisy.append(init_model.noise)\n",
    "            if j!= 0 or former_objective != obj:\n",
    "                y_next = former_objective(x1=x_next.T[0:1].T, x2=x_next.T[1:2].T, noise=noise)\n",
    "                init_model.add_Observation(x_next, y_next)\n",
    "                init_model.update()\n",
    "                \n",
    "            mean_hmaps = []\n",
    "            \n",
    "            # inner loop: plot all categories\n",
    "            for x_test_inner, obj_inner, title in zip([X_test1, X_test2, X_test3, X_test4],\n",
    "                                                      [obj1, obj2, obj3, obj4],\n",
    "                                                      [1,2,3,4]):\n",
    "                data = [(x.item(), y.item(), z.item())\n",
    "                        for x,y,z in zip(x_test.T[0].T,\n",
    "                                         x_test.T[1].T,\n",
    "                                         init_model(x_test_inner)[0].data)]\n",
    "                \n",
    "                X, _ = getCateg(init_model, x_test_inner[0].T[2:].T)\n",
    "                \n",
    "                train_points = hv.Points((X.T[0].T, X.T[1]), label='Iterate Points').opts(color='black', size=5)\n",
    "                if init_samples is not None:\n",
    "                    train_points = train_points * hv.Points((init_samples[(title-1)*20: title*20+20].T[0].T,\n",
    "                                                             init_samples[(title-1)*20: title*20+20].T[1].T),\n",
    "                                                            label='Initial Points').opts(color='orange', size=5)\n",
    "                new_plot = hv.HeatMap(data).opts(cmap='RdBu_r', width=width, height=height, colorbar=True,\n",
    "                                                 title='Mean prediction {}:\\n {:.4f}'.format(title,\n",
    "                                                                                              init_model.kernel.module_2.weight.T[title-1].T.item()),\n",
    "                                                 xlabel=xlabel,\n",
    "                                                 ylabel=ylabel)\n",
    "                \n",
    "                data = [(x.item(), y.item(), z.item()) for x,y,z in zip(x_test.T[0].T,\n",
    "                                                                        x_test.T[1].T,\n",
    "                                                                        init_model(x_test_inner)[1].data)]\n",
    "                \n",
    "                unc_plot = hv.HeatMap(data).opts(cmap='RdBu_r', width=width, height=height, colorbar=True,\n",
    "                                                 title='Uncertainty {}'.format(title),\n",
    "                                                 xlabel=xlabel,\n",
    "                                                 ylabel=ylabel)\n",
    "                \n",
    "                if (x_test == x_test_inner).all():\n",
    "                    x_next = init_model.next_sample(x_test).data\n",
    "                    next_plot = hv.Points(x_next, label='Next sample').opts(marker='diamond', color='#999999', size=23)\n",
    "                    \n",
    "                    mean_hmaps.append(\n",
    "                        ((new_plot*next_plot*train_points).opts(show_legend=False, fontsize=fontsize)\n",
    "                         + (unc_plot*next_plot*train_points).opts(show_legend=False, fontsize=fontsize)))\n",
    "                    \n",
    "                    acq_values = init_model.get_acq_values(x_test)\n",
    "                    data = [(x.item(), y.item(), z.item()) for x,y,z in zip(x_test.T[0].T, x_test.T[1].T, acq_values)]\n",
    "                    acq_hmap = hv.HeatMap(data).opts(cmap='plasma', width=width, height=height+80, colorbar=True,\n",
    "                                                     title='Acquisition Function (categ {})'.format(title),\n",
    "                                                     xlabel=xlabel,\n",
    "                                                     ylabel=ylabel, fontsize=fontsize) * next_plot * train_points\n",
    "                    acq_hmap = acq_hmap.opts(show_legend=True, legend_position='bottom')\n",
    "                else:\n",
    "                    mean_hmaps.append((new_plot*train_points).opts(show_legend=False, fontsize=fontsize)\n",
    "                                      + (unc_plot*train_points).opts(show_legend=False, fontsize=fontsize))\n",
    "                    \n",
    "            hmaps[len(hmaps)] = (  mean_hmaps[0][0].opts(fontsize=fontsize) + mean_hmaps[0][1]\n",
    "                                 + mean_hmaps[1][0] + mean_hmaps[1][1]\n",
    "                                 + mean_hmaps[2][0] + mean_hmaps[2][1]\n",
    "                                 + mean_hmaps[3][0] + mean_hmaps[3][1]\n",
    "                                 + acq_hmap).opts(shared_axes=False).cols(2)\n",
    "            \n",
    "            former_objective = obj\n",
    "            \n",
    "            \n",
    "    return hmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5d507",
   "metadata": {},
   "source": [
    "## extended BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad21d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 initial samples per category, 80 in total\n",
    "num_init = 20\n",
    "noise = 0.\n",
    "\n",
    "X_init1 = torch.cat((torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.tensor([1,0,0,0]).repeat(num_init,1)), dim=1)\n",
    "y_init1_nf = obj1(x1=X_init1.T[0:1].T, x2=X_init1.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "X_init2 = torch.cat((torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.tensor([0,1,0,0]).repeat(num_init,1)), dim=1)\n",
    "y_init2_nf = obj2(x1=X_init2.T[0:1].T, x2=X_init2.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "X_init3 = torch.cat((torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.tensor([0,0,1,0]).repeat(num_init,1)), dim=1)\n",
    "y_init3_nf = obj3(x1=X_init3.T[0:1].T, x2=X_init3.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "X_init4 = torch.cat((torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.rand(num_init, 1, dtype=torch.float64)*10,\n",
    "                     torch.tensor([0,0,0,1]).repeat(num_init,1)), dim=1)\n",
    "y_init4_nf = obj4(x1=X_init4.T[0:1].T, x2=X_init4.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "X_init = torch.cat((X_init1, X_init2, X_init3, X_init4), dim=0)\n",
    "y_init_nf = torch.cat((y_init1_nf, y_init2_nf, y_init3_nf, y_init4_nf), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "kappa = 10.\n",
    "\n",
    "kernel = TransformationKernel(input_dim = input_dim,\n",
    "                              trans_mappings=OrderedDict({(0,): lambda x:x,\n",
    "                                                          (1,): lambda x:x.round(),\n",
    "                                                          (2,3,4,5): torch.nn.Linear(4,1,bias=False, dtype=torch.float64)}))\n",
    "\n",
    "bo_model_nf = PyroBO(X_init, y_init_nf, kernel=kernel, acq_fun=ConfidenceBound(input_dim=input_dim,\n",
    "                                                                               kappa=kappa,\n",
    "                                                                               maximize=True))\n",
    "bo_model_nf.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f52eb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_iter=4 # number of iterations per category\n",
    "noise = 0.\n",
    "\n",
    "lengthscale = []\n",
    "outputscale = []\n",
    "noise_ = []\n",
    "\n",
    "hmap_nf = hv.HoloMap(getHmaps(bo_model_nf, num_iter=num_iter, init_samples=X_init), kdims='iteration')\n",
    "hv.output(hmap_nf.collate(), widget_location='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(hmap_nf.collate(), 'Combine_All.auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d57c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('plotly')\n",
    "\n",
    "lengthscale_nf_plot = hv.Curve((torch.tensor(lengthscale))).opts(height=200)\n",
    "outputscale_nf_plot = hv.Curve((torch.tensor(outputscale))).opts(height=200)\n",
    "noise_nf_plot = hv.Curve((torch.tensor(noise_))).opts(height=200)\n",
    "\n",
    "(lengthscale_nf_plot + outputscale_nf_plot + noise_nf_plot).opts(shared_axes=False).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbd0a2",
   "metadata": {},
   "source": [
    "## extended BO - noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33454a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.5\n",
    "\n",
    "y_init1_noisy = obj1(x1=X_init1.T[0:1].T, x2=X_init1.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "y_init2_noisy = obj2(x1=X_init2.T[0:1].T, x2=X_init2.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "y_init3_noisy = obj3(x1=X_init3.T[0:1].T, x2=X_init3.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "y_init4_noisy = obj4(x1=X_init4.T[0:1].T, x2=X_init4.T[1].T.reshape(-1,1), noise=noise)\n",
    "\n",
    "y_init_noisy = torch.cat((y_init1_noisy, y_init2_noisy, y_init3_noisy, y_init4_noisy), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = TransformationKernel(input_dim = input_dim,\n",
    "                              trans_mappings=OrderedDict({(0,): lambda x:x,\n",
    "                                                          (1,): lambda x:x.round(),\n",
    "                                                          (2,3,4,5): torch.nn.Linear(4,1,bias=False,\n",
    "                                                                                     dtype=torch.float64)}))\n",
    "\n",
    "bo_model_noisy = PyroBO(X_init, y_init_noisy, kernel=kernel, acq_fun=ConfidenceBound(input_dim=input_dim,\n",
    "                                                                                     kappa=kappa,\n",
    "                                                                                     maximize=True))\n",
    "bo_model_noisy.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "\n",
    "lengthscale_noisy = []\n",
    "outputscale_noisy = []\n",
    "noise_noisy = []\n",
    "\n",
    "hmap_noisy = hv.HoloMap(getHmaps(bo_model_noisy, num_iter=num_iter, init_samples=(X_init)), kdims='iteration')\n",
    "hv.output(hmap_noisy.collate(), widget_location='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0585d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(hmap_noisy.collate(), 'Combine_All_noisy.auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('plotly')\n",
    "\n",
    "lengthscale_noisy_plot = hv.Curve((torch.tensor(lengthscale_noisy))).opts(height=200)\n",
    "outputscale_noisy_plot = hv.Curve((torch.tensor(outputscale_noisy))).opts(height=200)\n",
    "noise_noisy_plot = hv.Curve((torch.tensor(noise_noisy))).opts(height=200)\n",
    "\n",
    "(lengthscale_noisy_plot + outputscale_noisy_plot + noise_noisy_plot).opts(shared_axes=False).cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee450f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
